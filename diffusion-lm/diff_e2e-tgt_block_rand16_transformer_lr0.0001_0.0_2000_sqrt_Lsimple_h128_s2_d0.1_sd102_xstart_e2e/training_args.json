{
  "data_dir": "",
  "schedule_sampler": "uniform",
  "lr": 0.0001,
  "weight_decay": 0.0,
  "lr_anneal_steps": 200000,
  "batch_size": 64,
  "microbatch": -1,
  "ema_rate": "0.9999",
  "log_interval": 50,
  "save_interval": 50000,
  "resume_checkpoint": "",
  "use_fp16": false,
  "fp16_scale_growth": 0.001,
  "seed": 102,
  "gradient_clipping": -1.0,
  "eval_interval": 2000,
  "checkpoint_path": "diffusion_models/diff_e2e-tgt_block_rand16_transformer_lr0.0001_0.0_2000_sqrt_Lsimple_h128_s2_d0.1_sd102_xstart_e2e",
  "image_size": 8,
  "num_channels": 128,
  "num_res_blocks": 2,
  "num_heads": 4,
  "num_heads_upsample": -1,
  "attention_resolutions": "16,8",
  "dropout": 0.1,
  "learn_sigma": false,
  "sigma_small": false,
  "class_cond": false,
  "diffusion_steps": 2000,
  "noise_schedule": "sqrt",
  "timestep_respacing": "",
  "use_kl": false,
  "predict_xstart": true,
  "rescale_timesteps": true,
  "rescale_learned_sigmas": true,
  "use_checkpoint": false,
  "use_scale_shift_norm": true,
  "model_arch": "transformer",
  "in_channel": 16,
  "out_channel": 16,
  "training_mode": "e2e",
  "vocab_size": 821,
  "config_name": "bert-base-uncased",
  "experiment_mode": "lm",
  "logits_mode": 1,
  "modality": "e2e-tgt",
  "dataset_name": "wikitext",
  "dataset_config_name": "wikitext-2-raw-v1",
  "config": "diffusion_lm/synthetic_data/configs/emnlp2020/experiments/difflm_seed0_m3_k128_trainc20000.yaml",
  "model_name_or_path": "predictability/diff_models/compress_e=5_b=60_m=gpt2_wikitext-103-raw-v1_None",
  "experiment": "random",
  "roc_train": "diffusion_lm/ROCstory",
  "wiki_train": "diffusion_lm/simple_wiki/data.v1.split/simple.training.txt",
  "e2e_train": "../datasets/e2e_data",
  "yelp_train": "diffusion_lm/yelpnlg-resources/yelpnlg-corpus",
  "commonGen_train": "diffusion_lm/common-gen/commongen_data",
  "emb_scale_factor": 1.0,
  "noise_level": 0.0,
  "cache_mode": "no",
  "use_bert_tokenizer": "no",
  "padding_mode": "block",
  "preprocessing_num_workers": 1
}